# @package _global_

# Experiment 1XX: FULL MODEL - All Compatible Enhancements
# Combines: Deep Supervision + Squeeze-and-Excitation + Spatial Encoding
# This is the best configuration for maximum performance

defaults:
  - override /data: isic2017
  - override /model: mk_enhanced
  - override /callbacks: default
  - override /trainer: default
  - override /logger: wandb

# Experiment name
experiment_name: "exp1XX_full_enhanced"

# Seed
seed: 12345

# Tags for logging
tags: ["exp1XX", "full_model", "DS+SE+Spatial", "best_config", "mk_unet"]

# Data configuration
data:
  spatial_mode: "rgb_xyz_radial"  # ✅ Spatial encoding
  in_channels: 6
  batch_size: 16
  num_workers: 4

# Model configuration - ALL FEATURES ENABLED
model:
  net:
    in_channels: 6
    channels: [16, 32, 64, 96]  # Kept small for fast training
    use_spatial: true  # ✅ Enable spatial encoding
    use_se: true  # ✅ Enable Squeeze-and-Excitation
    deep_supervision: true  # ✅ Enable Deep Supervision
  
  optimizer:
    lr: 0.001
    weight_decay: 0.0001
  
  criterion:
    dice_weight: 0.6
    bce_weight: 0.4
    aux_weight: 0.4  # Weight for auxiliary DS losses

# Trainer configuration - Extended for best results
trainer:
  max_epochs: 80  # More epochs for full model
  accelerator: gpu
  devices: 1
  precision: 16-mixed
  log_every_n_steps: 10
  check_val_every_n_epoch: 1
  gradient_clip_val: 1.0  # Gradient clipping for stability

# Callbacks
callbacks:
  model_checkpoint:
    monitor: "val/dice"
    mode: "max"
    save_top_k: 3  # Save top 3 models
    filename: "epoch_{epoch:03d}_dice_{val/dice:.4f}"
  
  early_stopping:
    monitor: "val/dice"
    patience: 20  # More patience for full model
    mode: "max"

# Logger
logger:
  wandb:
    project: "umambaspa-lesion"
    name: "exp1XX_full_enhanced"
    tags: ${tags}
    notes: |
      FULL ENHANCED MODEL - Maximum Performance Configuration
      
      Features enabled:
      - ✅ Deep Supervision (multi-level auxiliary losses)
      - ✅ Squeeze-and-Excitation (channel attention)
      - ✅ Spatial Encoding (X, Y, Radial position features)
      
      Expected improvements:
      - Deep Supervision: +2-3% Dice
      - SE Attention: +1-1.5% Dice  
      - Spatial Encoding: +1-2% Dice
      - Total expected: +4-6% over baseline
      
      Architecture: Lightweight MK U-Net (no Mamba for fast training)
      Parameters: ~0.7M (efficient for quick iteration)
